{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6839e86",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecda26c",
   "metadata": {},
   "source": [
    "#### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e920902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with url=['https://www.federalreserve.gov/newsevents/pressreleases.htm']\n",
      "List of URLs which contain covid:\n",
      "https://www.federalreserve.gov/newsevents/pressreleases/2021-press.htm\n",
      "https://www.federalreserve.gov/newsevents/pressreleases/2020-press.htm\n",
      "https://www.federalreserve.gov/newsevents/pressreleases/monetary20220615a.htm\n",
      "https://www.federalreserve.gov/newsevents/pressreleases/monetary20220504a.htm\n",
      "https://www.federalreserve.gov/newsevents/pressreleases/monetary20220126a.htm\n",
      "https://www.federalreserve.gov/newsevents/pressreleases/other20220523a.htm\n",
      "https://www.federalreserve.gov/newsevents/pressreleases/enforcement20220405a.htm\n",
      "https://www.federalreserve.gov/newsevents/pressreleases/other20220225a.htm\n",
      "https://www.federalreserve.gov/newsevents/pressreleases/bcreg20220214a.htm\n",
      "https://www.federalreserve.gov/newsevents/pressreleases/other20220114a.htm\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "seed_url = \"https://www.federalreserve.gov/newsevents/pressreleases.htm\"\n",
    "\n",
    "urls = [seed_url]\n",
    "seen = [seed_url]\n",
    "opened = []\n",
    "contain_covid = []\n",
    "\n",
    "maxNumUrl = 10; \n",
    "print(\"Starting with url=\"+str(urls))\n",
    "\n",
    "while len(urls) > 0 and len(contain_covid) < maxNumUrl:\n",
    "    try:\n",
    "        curr_url=urls.pop(0)\n",
    "        #print(\"Trying to access= \"+curr_url)\n",
    "        req = urllib.request.Request(curr_url,headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        webpage = urllib.request.urlopen(req).read()\n",
    "        opened.append(curr_url)\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(\"Unable to access= \"+curr_url)\n",
    "        print(ex)\n",
    "        continue   \n",
    "    \n",
    "    soup = BeautifulSoup(webpage)\n",
    "    \n",
    "    webpage_text = soup.get_text().split()\n",
    "    for word in webpage_text:\n",
    "        word = word.lower()\n",
    "        if 'covid' in word:\n",
    "            contain_covid.append(curr_url)\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    for tag in soup.find_all('a', href = True):\n",
    "        childUrl = tag['href']\n",
    "        o_childurl = childUrl\n",
    "        childUrl = urllib.parse.urljoin(seed_url, childUrl)\n",
    "        \n",
    "        if seed_url[:-4] in childUrl and childUrl not in seen:\n",
    "            urls.append(childUrl)\n",
    "            seen.append(childUrl)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "print(\"List of URLs which contain covid:\")\n",
    "for url in contain_covid:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316ffc87",
   "metadata": {},
   "source": [
    "#### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d660429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with url=['https://www.sec.gov/news/pressreleases']\n",
      "seed\n",
      "https://www.sec.gov/news/pressreleases\n",
      "\n",
      "\n",
      "      Skip to main content\n",
      "    \n",
      "https://www.sec.gov/news/pressreleases#main-content\n",
      "\n",
      "Press Releases\n",
      "https://www.sec.gov/news/pressreleases.rss\n",
      "\n",
      "Executives Charged With Manipulating Company's Accounting Systems to Steal Money\n",
      "https://www.sec.gov/news/pressrelease/2017-64.html\n",
      "\n",
      "SEC Charges Firms Involved in Layering, Manipulation Schemes\n",
      "https://www.sec.gov/news/pressrelease/2017-63.html\n",
      "\n",
      "SEC Charges Marijuana-Related Company and Executives With Touting Bogus Revenues\n",
      "https://www.sec.gov/news/pressrelease/2017-62.html\n",
      "\n",
      "SEC Charges Mexico-Based Homebuilder in $3.3 Billion Accounting Fraud \n",
      "https://www.sec.gov/news/pressrelease/2017-60.html\n",
      "\n",
      "SEC Staff Issues Guidance Update and Investor Bulletin on Robo-Advisers\n",
      "https://www.sec.gov/news/pressrelease/2017-52.html\n",
      "\n",
      "SEC Charges Chinese Citizens Who Reaped Massive Profits From Insider Trading on Comcast-Dreamworks Acquisition\n",
      "https://www.sec.gov/news/pressrelease/2017-44.html\n",
      "\n",
      "Company Settles Charges in Whistleblower Retaliation Case\n",
      "https://www.sec.gov/news/pressrelease/2016-270.html\n",
      "\n",
      "PIMCO Settles Charges of Misleading Investors About ETF Performance\n",
      "https://www.sec.gov/news/pressrelease/2016-252.html\n",
      "\n",
      "SEC Charges Asset Management Fund and Manager \n",
      "https://www.sec.gov/news/pressrelease/2016-250.html\n",
      "\n",
      "Brokerage Firm Charged With Anti-Money Laundering Failures\n",
      "https://www.sec.gov/news/pressrelease/2016-102.html\n",
      "\n",
      "SEC Charges Oregon-Based Investment Group and Executives With Defrauding Investors\n",
      "https://www.sec.gov/news/pressrelease/2016-49.html\n",
      "\n",
      "SEC Names C. Dabney Oâ€™Riordan and Alka Patel as Associate Regional Directors in Los Angeles Office\n",
      "https://www.sec.gov/news/pressrelease/2016-26.html\n",
      "\n",
      "SEC to Hold Equity Market Structure Advisory Committee Meeting on October 27\n",
      "https://www.sec.gov/news/pressrelease/2015-216.html\n",
      "\n",
      "SEC Charges Florida-Based CPA with Fraud for Issuing Bogus Audit Opinions\n",
      "https://www.sec.gov/news/pressrelease/2015-195.html\n",
      "\n",
      "SEC Announces Fraud Charges in Cross-Border Scheme to Secretly Control and Manipulate Stock of Chinese Companies After Reverse Mergers\n",
      "https://www.sec.gov/news/pressrelease/2015-189.html\n",
      "\n",
      "SEC Charges 32 Defendants in Scheme to Trade on Hacked News Releases\n",
      "https://www.sec.gov/news/pressrelease/2015-163.html\n",
      "\n",
      "SEC Charges Oregon-Based Defense Contractor With FCPA Violations\n",
      "https://www.sec.gov/news/pressrelease/2015-62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "seed_url = \"https://www.sec.gov/news/pressreleases\"\n",
    "\n",
    "urls = [seed_url]\n",
    "url_text = ['seed']\n",
    "seen = [seed_url]\n",
    "opened = []\n",
    "contain_charges = []\n",
    "\n",
    "maxNumUrl = 20; \n",
    "print(\"Starting with url=\"+str(urls))\n",
    "\n",
    "while len(urls) > 0 and len(contain_charges) < maxNumUrl:\n",
    "    try:\n",
    "        curr_url=urls.pop(0)\n",
    "        curr_text=url_text.pop(0)\n",
    "        req = urllib.request.Request(curr_url,headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        webpage = urllib.request.urlopen(req).read()\n",
    "        opened.append(curr_url)\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(\"Unable to access= \"+curr_url)\n",
    "        print(ex)\n",
    "        continue   \n",
    "    \n",
    "    soup = BeautifulSoup(webpage)\n",
    "    \n",
    "    webpage_text = soup.get_text().split()\n",
    "    for word in webpage_text:\n",
    "        word = word.lower()\n",
    "        if 'charges' in word:\n",
    "            print(curr_text)\n",
    "            print(curr_url)\n",
    "            print('')\n",
    "            contain_charges.append(curr_url)\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    for tag in soup.find_all('a', href = True):\n",
    "        childUrl = tag['href']\n",
    "        o_childurl = childUrl\n",
    "        childUrl = urllib.parse.urljoin(seed_url, childUrl)\n",
    "        tag_text = tag.text\n",
    "        \n",
    "        if seed_url[:-4] in childUrl and childUrl not in seen:\n",
    "            urls.append(childUrl)\n",
    "            url_text.append(tag_text)\n",
    "            seen.append(childUrl)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da708e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf1ff12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
